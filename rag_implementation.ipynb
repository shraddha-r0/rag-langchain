{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f539436",
   "metadata": {},
   "source": [
    "## Implementation of a simple RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed936f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb046d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 37 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 37 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Load PDFs\n",
    "pdf_folder = Path(\"pdfs/\")\n",
    "\n",
    "all_docs = []\n",
    "for pdf_file in pdf_folder.glob(\"*.pdf\"):\n",
    "    loader = PyPDFLoader(str(pdf_file))\n",
    "    all_docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4159aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the data using recursive chunking\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a23f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1b01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/0d/_4fqv2g50f36w1vmz28wqkyr0000gn/T/ipykernel_46303/3190493980.py:9: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# Store the embeddings locally in ChromaDB\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3be4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-small\"  # Or try flan-t5-base if M2 can handle it\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Create text2text pipeline (note: temperature may be ignored)\n",
    "hf_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Wrap in LangChain HuggingFace LLM (new path!)\n",
    "hf_llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c0092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=hf_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2e6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ornithology ornithology\n"
     ]
    }
   ],
   "source": [
    "response = hf_llm.invoke(\"What is ornithology?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb9568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ LLM-Only Response:\n",
      " Ornithology\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üî∏ RAG-Augmented Response:\n",
      " {'query': 'What is ornithology?', 'result': 'Ornithology is a branch of science devoted to the study of birds. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is ornithology?\"\n",
    "\n",
    "# ‚úÖ RAG response (using LangChain's new `.invoke()` method)\n",
    "response_rag = qa_chain.invoke(query)\n",
    "\n",
    "# ‚úÖ LLM-only response\n",
    "ragless_prompt = f\"Answer the following question:\\n{query}\"\n",
    "response_llm_only = hf_llm.invoke(ragless_prompt)\n",
    "\n",
    "# üìä Display the results\n",
    "print(\"üîπ LLM-Only Response:\\n\", response_llm_only)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üî∏ RAG-Augmented Response:\\n\", response_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138caa4",
   "metadata": {},
   "source": [
    "### Test with Open AI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044d0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set. Please set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09878d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prompt template with RAG context\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template='''\n",
    "    Given the context below, answer the question to the best of your ability.\n",
    "    Be polite and helpful.\n",
    "    If the context doesn't contain the answer, say \"I don't know\" and offer to help with something else.\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb20c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/_4fqv2g50f36w1vmz28wqkyr0000gn/T/ipykernel_46303/2701949801.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
      "/var/folders/0d/_4fqv2g50f36w1vmz28wqkyr0000gn/T/ipykernel_46303/2701949801.py:20: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rag_response = rag_chain({\"query\": query})\n",
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ LLM-Only Response:\n",
      " The main functions of bird feathers are insulation, flight, protection, and display.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîπ RAG-Augmented Response:\n",
      " The main functions of bird feathers include insulation, waterproofing, flight, communication, and camouflage.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ‚úÖ LLM Setup\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# ‚úÖ Retrieval setup (RAG)\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template}\n",
    ")\n",
    "# ‚úÖ Query to compare\n",
    "query = \"What are the main functions of bird feathers?\"\n",
    "\n",
    "# üî∏ 1. LLM-Only (No RAG)\n",
    "llm_only_prompt = f\"Answer the following question clearly and concisely:\\n\\n{query}\"\n",
    "llm_only_response = llm.invoke(llm_only_prompt)\n",
    "\n",
    "# üîπ 2. RAG-Based (uses retrieved context)\n",
    "rag_response = rag_chain({\"query\": query})\n",
    "\n",
    "# üñ•Ô∏è Print Results\n",
    "print(\"üî∏ LLM-Only Response:\\n\", llm_only_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üîπ RAG-Augmented Response:\\n\", rag_response['result'])\n",
    "print(\"\\nSources:\")\n",
    "    for doc in rag_response[\"source_documents\"]:\n",
    "        print(f\"- {doc.metadata.get('source', 'Unknown source')}, page {doc.metadata.get('page', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60dfecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ LLM-Only Response:\n",
      " Songbirds are diverse due to a combination of factors such as their ability to adapt to various habitats, their wide range of diets, and their complex vocalizations for communication and mating purposes.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîπ RAG-Augmented Response:\n",
      " Songbirds are diverse due to their ability to learn songs and other mate-attracting or territory-protecting behaviors, which are potential key innovations that drive their diversity.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Query to compare\n",
    "query = \"Why are songbirds so diverse? Be brief.\"\n",
    "\n",
    "# üî∏ 1. LLM-Only (No RAG)\n",
    "llm_only_prompt = f\"Answer the following question clearly and concisely:\\n\\n{query}\"\n",
    "llm_only_response = llm.invoke(llm_only_prompt)\n",
    "\n",
    "# üîπ 2. RAG-Based (uses retrieved context)\n",
    "rag_response = rag_chain({\"query\": query})\n",
    "\n",
    "# üñ•Ô∏è Print Results\n",
    "print(\"üî∏ LLM-Only Response:\\n\", llm_only_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üîπ RAG-Augmented Response:\\n\", rag_response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63aca748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ LLM-Only Response:\n",
      " | Aspect          | Bird Bones                  | Human Bones                 |\n",
      "|-----------------|-----------------------------|-----------------------------|\n",
      "| Structure       | Hollow and lightweight      | Dense and solid             |\n",
      "| Composition     | Mostly made of calcium      | Mostly made of calcium      |\n",
      "| Function        | Aid in flight and balance   | Support body weight and movement |\n",
      "| Number          | More numerous and smaller   | Fewer and larger            |\n",
      "| Growth          | Can repair and remodel quickly | Slower repair and remodeling |\n",
      "| Strength        | Strong but more fragile     | Strong and less fragile     |\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîπ RAG-Augmented Response:\n",
      " | Aspect          | Bird Bones                               | Human Bones                              |\n",
      "|-----------------|------------------------------------------|------------------------------------------|\n",
      "| Structure       | Highly specialized for flying            | Not specialized for flying               |\n",
      "| Missing Bones   | None                                     | Some bones missing or fused with others  |\n",
      "| Motion          | Bones move differently on each other      | Bones move differently on each other      |\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Query to compare\n",
    "query = \"How are bird bones similar and different to that of humans? Answer in a tabular form\"\n",
    "\n",
    "# üî∏ 1. LLM-Only (No RAG)\n",
    "llm_only_prompt = f\"Answer the following question clearly and concisely:\\n\\n{query}\"\n",
    "llm_only_response = llm.invoke(llm_only_prompt)\n",
    "\n",
    "# üîπ 2. RAG-Based (uses retrieved context)\n",
    "rag_response = rag_chain({\"query\": query})\n",
    "\n",
    "# üñ•Ô∏è Print Results\n",
    "print(\"üî∏ LLM-Only Response:\\n\", llm_only_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üîπ RAG-Augmented Response:\\n\", rag_response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb7324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
