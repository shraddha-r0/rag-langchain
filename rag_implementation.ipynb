{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f539436",
   "metadata": {},
   "source": [
    "## Implementation of a simple RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed936f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb046d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 37 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 37 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# Load PDFs\n",
    "pdf_folder = Path(\"pdfs/\")\n",
    "\n",
    "all_docs = []\n",
    "for pdf_file in pdf_folder.glob(\"*.pdf\"):\n",
    "    loader = PyPDFLoader(str(pdf_file))\n",
    "    all_docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4159aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the data using recursive chunking\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a23f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1b01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/var/folders/0d/_4fqv2g50f36w1vmz28wqkyr0000gn/T/ipykernel_40220/3190493980.py:9: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# Store the embeddings locally in ChromaDB\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3be4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-small\"  # Or try flan-t5-base if M2 can handle it\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Create text2text pipeline (note: temperature may be ignored)\n",
    "hf_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Wrap in LangChain HuggingFace LLM (new path!)\n",
    "hf_llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c0092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=hf_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2e6bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ornithology ornithology\n"
     ]
    }
   ],
   "source": [
    "response = hf_llm.invoke(\"What is ornithology?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb9568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ LLM-Only Response:\n",
      " Ornithology\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üî∏ RAG-Augmented Response:\n",
      " {'query': 'What is ornithology?', 'result': 'Ornithology is a branch of science devoted to the study of birds. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research involving birds, such as habitat studies and migration patterns. Ornithology encompasses all types of research'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is ornithology?\"\n",
    "\n",
    "# ‚úÖ RAG response (using LangChain's new `.invoke()` method)\n",
    "response_rag = qa_chain.invoke(query)\n",
    "\n",
    "# ‚úÖ LLM-only response\n",
    "ragless_prompt = f\"Answer the following question:\\n{query}\"\n",
    "response_llm_only = hf_llm.invoke(ragless_prompt)\n",
    "\n",
    "# üìä Display the results\n",
    "print(\"üîπ LLM-Only Response:\\n\", response_llm_only)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üî∏ RAG-Augmented Response:\\n\", response_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "044d0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set. Please set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9fb20c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/_4fqv2g50f36w1vmz28wqkyr0000gn/T/ipykernel_40220/2873170741.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ LLM-Only Response:\n",
      " The main functions of bird feathers are insulation, flight, protection, and display.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîπ RAG-Augmented Response:\n",
      " Bird feathers serve several important functions, including insulation to regulate body temperature, providing lift and aiding in flight, waterproofing to maintain buoyancy and protect against water, camouflage for blending into the environment, communication through displays and signals, and protection from physical harm and UV radiation.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# ‚úÖ LLM Setup\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# ‚úÖ Retrieval setup (RAG)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Query to compare\n",
    "query = \"What are the main functions of bird feathers?\"\n",
    "\n",
    "# üî∏ 1. LLM-Only (No RAG)\n",
    "llm_only_prompt = f\"Answer the following question clearly and concisely:\\n\\n{query}\"\n",
    "llm_only_response = llm.invoke(llm_only_prompt)\n",
    "\n",
    "# üîπ 2. RAG-Based (uses retrieved context)\n",
    "rag_response = rag_chain.invoke(query)\n",
    "\n",
    "# üñ•Ô∏è Print Results\n",
    "print(\"üî∏ LLM-Only Response:\\n\", llm_only_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üîπ RAG-Augmented Response:\\n\", rag_response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b60dfecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ LLM-Only Response:\n",
      " Songbirds are diverse due to a combination of factors such as their ability to adapt to various habitats, their wide range of diets, and their unique vocalizations for communication and mating purposes.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîπ RAG-Augmented Response:\n",
      " Songbirds are diverse due to potential key innovations like the ability to learn songs, high levels of sexual dimorphism and sexual selection, and behaviors related to migration and dispersal ability. These characteristics allow for diversification as new species extend into new areas or take advantage of new resources.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Query to compare\n",
    "query = \"Why are songbirds so diverse? Be brief.\"\n",
    "\n",
    "# üî∏ 1. LLM-Only (No RAG)\n",
    "llm_only_prompt = f\"Answer the following question clearly and concisely:\\n\\n{query}\"\n",
    "llm_only_response = llm.invoke(llm_only_prompt)\n",
    "\n",
    "# üîπ 2. RAG-Based (uses retrieved context)\n",
    "rag_response = rag_chain.invoke(query)\n",
    "\n",
    "# üñ•Ô∏è Print Results\n",
    "print(\"üî∏ LLM-Only Response:\\n\", llm_only_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üîπ RAG-Augmented Response:\\n\", rag_response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63aca748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraddharamesh/Documents/Artificial Intelligence/GitHub Projects/outskill-ai-practice/rag-langchain/rag/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ LLM-Only Response:\n",
      " | Aspect          | Bird Bones                  | Human Bones                 |\n",
      "|-----------------|-----------------------------|-----------------------------|\n",
      "| Structure       | Hollow and lightweight      | Dense and solid             |\n",
      "| Composition     | Mostly made of calcium      | Mostly made of calcium      |\n",
      "| Function        | Aid in flight and balance   | Support body weight and movement |\n",
      "| Number          | More numerous and smaller   | Fewer and larger            |\n",
      "| Growth          | Can repair and regrow       | Limited ability to repair    |\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîπ RAG-Augmented Response:\n",
      " I'm sorry, but I cannot provide a tabular form response. Would you like a detailed comparison instead?\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Query to compare\n",
    "query = \"How are bird bones similar and different to that of humans? Answer in a tabular form\"\n",
    "\n",
    "# üî∏ 1. LLM-Only (No RAG)\n",
    "llm_only_prompt = f\"Answer the following question clearly and concisely:\\n\\n{query}\"\n",
    "llm_only_response = llm.invoke(llm_only_prompt)\n",
    "\n",
    "# üîπ 2. RAG-Based (uses retrieved context)\n",
    "rag_response = rag_chain.invoke(query)\n",
    "\n",
    "# üñ•Ô∏è Print Results\n",
    "print(\"üî∏ LLM-Only Response:\\n\", llm_only_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"üîπ RAG-Augmented Response:\\n\", rag_response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb7324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
